{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0e1b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c868661",
   "metadata": {},
   "source": [
    "STEP1. Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd9f2c",
   "metadata": {},
   "source": [
    "mkdir -p ~/work/transformer_chatbot/data/ && cd ~/work/transformer_chatbot/data/\n",
    "\n",
    "$ wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fecaad",
   "metadata": {},
   "source": [
    "STEP2. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ÌïòÍ∏∞\n",
    "- ÏòÅÏñ¥ Îç∞Ïù¥ÌÑ∞ÏôÄÎäî Ï†ÑÌòÄ Îã§Î•∏ Îç∞Ïù¥ÌÑ∞Ïù∏ ÎßåÌÅº ÏòÅÏñ¥ Îç∞Ïù¥ÌÑ∞Ïóê ÏÇ¨Ïö©ÌñàÎçò Ï†ÑÏ≤òÎ¶¨ÏôÄ ÏùºÎ∂Ä ÎèôÏùºÌïú Ï†ÑÏ≤òÎ¶¨ÎèÑ ÌïÑÏöîÌïòÍ≤†ÏßÄÎßå Ï†ÑÏ≤¥Ï†ÅÏúºÎ°úÎäî Îã§Î•∏ Ï†ÑÏ≤òÎ¶¨Î•º ÏàòÌñâÌï¥Ïïº Ìï† ÏàòÎèÑ ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e93508c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ÏïàÎÖïÌïòÏÑ∏Ïöî ! Ï†ÄÎäî ÌïôÏÉùÏûÖÎãàÎã§ . , ÎßåÎÇòÏÑú Î∞òÍ∞ëÏäµÎãàÎã§ . !\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = \"C:/Users/user/Desktop/ChatbotData.csv\"\n",
    "MAX_SAMPLES = 300000\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
    "def preprocess_sentence(sentence):\n",
    "  # ÏûÖÎ†•Î∞õÏùÄ sentenceÎ•º ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÍ≤ΩÌïòÍ≥† ÏñëÏ™Ω Í≥µÎ∞±ÏùÑ Ï†úÍ±∞\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # Îã®Ïñ¥ÏôÄ Íµ¨ÎëêÏ†ê(punctuation) ÏÇ¨Ïù¥Ïùò Í±∞Î¶¨Î•º ÎßåÎì≠ÎãàÎã§.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")Î•º Ï†úÏô∏Ìïú Î™®Îì† Î¨∏ÏûêÎ•º Í≥µÎ∞±Ïù∏ ' 'Î°ú ÎåÄÏ≤¥Ìï©ÎãàÎã§.\n",
    "  sentence = re.sub(r\"[^„Ñ±-„ÖéÍ∞Ä-Ìû£0-9?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "\n",
    "sample_sentence = \"Hello? ÏïàÎÖïÌïòÏÑ∏Ïöî! Ï†ÄÎäî ÌïôÏÉùÏûÖÎãàÎã§.üòä, ÎßåÎÇòÏÑú Î∞òÍ∞ëÏäµÎãàÎã§.!\"\n",
    "preprocessed_sentence = preprocess_sentence(sample_sentence)\n",
    "print(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f681cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îç∞Ïù¥ÌÑ∞ Î°úÎî©: C:/Users/user/Desktop/ChatbotData.csv\n",
      "Ï†ÑÏ≤¥ ÏÉòÌîå Ïàò : 11823\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌïòÎäî ÎèôÏãúÏóê Ï†ÑÏ≤òÎ¶¨ Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ ÏßàÎ¨∏Í≥º ÎãµÎ≥ÄÏùò ÏåçÏùÑ Ï†ÑÏ≤òÎ¶¨\n",
    "def read_korean_chatbot_data(path_to_csv, max_samples=300000):\n",
    "    print(f\"Îç∞Ïù¥ÌÑ∞ Î°úÎî©: {path_to_csv}\")\n",
    "    try:\n",
    "        # ChatbotData.csv ÌååÏùºÏùÄ 'utf-8' Ïù∏ÏΩîÎî©Ïù∏ Í≤ΩÏö∞Í∞Ä ÎßéÏäµÎãàÎã§.\n",
    "        df = pd.read_csv(path_to_csv, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        # ÎßåÏïΩ utf-8 Ïã§Ìå® Ïãú 'cp949' ÏãúÎèÑ\n",
    "        df = pd.read_csv(path_to_csv, encoding='cp949')\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        q_text = preprocess_sentence(row['Q'])\n",
    "        a_text = preprocess_sentence(row['A'])\n",
    "        \n",
    "        # Ï†ÑÏ≤òÎ¶¨ ÌõÑ ÎπÑÏñ¥ÏûàÏßÄ ÏïäÏùÄ ÏåçÎßå Ï∂îÍ∞Ä\n",
    "        if q_text and a_text:\n",
    "            pairs.append((q_text, a_text))\n",
    "        \n",
    "        if len(pairs) >= max_samples:\n",
    "            print(f\"ÏµúÎåÄ {max_samples}Í∞ú ÏÉòÌîå Î°úÎî© ÏôÑÎ£å.\")\n",
    "            break\n",
    "            \n",
    "    return pairs\n",
    "\n",
    "#Î°úÎìúÌïú Îç∞Ïù¥ÌÑ∞Ïùò ÏÉòÌîå Ïàò ÌôïÏù∏\n",
    "pairs = read_korean_chatbot_data(path_to_dataset, max_samples=MAX_SAMPLES)\n",
    "\n",
    "print('Ï†ÑÏ≤¥ ÏÉòÌîå Ïàò :', len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52392a",
   "metadata": {},
   "source": [
    "STEP3. SentencePiece ÏÇ¨Ïö©ÌïòÍ∏∞\n",
    "- ÌïúÍµ≠Ïñ¥ Îç∞Ïù¥ÌÑ∞Îäî ÌòïÌÉúÏÜå Î∂ÑÏÑùÍ∏∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÌÜ†ÌÅ¨ÎÇòÏù¥ÏßïÏùÑ Ìï¥Ïïº ÌïúÎã§Í≥† ÎßéÏùÄ Î∂ÑÏù¥ ÏïåÍ≥† ÏûàÏäµÎãàÎã§. ÌïòÏßÄÎßå Ïó¨Í∏∞ÏÑúÎäî ÌòïÌÉúÏÜå Î∂ÑÏÑùÍ∏∞Í∞Ä ÏïÑÎãå ÏúÑ Ïã§ÏäµÏóêÏÑú ÏÇ¨Ïö©ÌñàÎçò ÏÑúÎ∏åÏõåÎìú ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÏù∏ SentencePieceÎ•º Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©Ìï¥Î≥¥ÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1bb3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÑÏ≤òÎ¶¨ ÌõÑÏùò Î¨∏Ïû•: ÎÇòÎäî ÏÑºÌÖêÏä§ÌîºÏä§Î°ú ÌååÏù¥ÌÜ†ÏπòÎ•º Î∞∞Ïö∞Í≥† ÏûàÏñ¥Ïöî\n",
      "Tokenized: ['‚ñÅÎÇòÎäî', '‚ñÅÏÑº', 'ÌÖê', 'Ïä§Ìîº', 'Ïä§Î°ú', '‚ñÅÌåå', 'Ïù¥', 'ÌÜ†', 'Ïπò', 'Î•º', '‚ñÅÎ∞∞Ïö∞', 'Í≥†', '‚ñÅÏûàÏñ¥Ïöî']\n",
      "Encoded: [688, 1858, 15136, 3600, 861, 860, 14788, 15406, 14960, 14845, 1072, 14797, 115]\n",
      "Decoded: ÎÇòÎäî ÏÑºÌÖêÏä§ÌîºÏä§Î°ú ÌååÏù¥ÌÜ†ÏπòÎ•º Î∞∞Ïö∞Í≥† ÏûàÏñ¥Ïöî\n"
     ]
    }
   ],
   "source": [
    "#1 Toklenizer ÌïôÏäµÌïòÍ∏∞\n",
    "    #ÏúÑÏóêÏÑú ÎßåÎì† pairÎ•º ÌÖçÏä§Ìä∏ ÌååÏùºÏóê Ï†ÄÏû•\n",
    "corpus_file = \"korean_chatbot_corpus.txt\"\n",
    "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "    for q, a in pairs:\n",
    "        f.write(q + \"\\n\")\n",
    "        f.write(a + \"\\n\")\n",
    "\n",
    "#ÏßàÎ¨∏-ÎãµÎ≥Ä ÏåçÏù¥ Îã¥Í∏¥ ÌååÏùºÏùÑ Ïù¥Ïö©Ìï¥ Î™®Îç∏ ÌõàÎ†®ÌïòÍ≥† ÌååÏùº ÏÉùÏÑ±\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=corpus_file,\n",
    "    model_prefix=\"spm_korean_chatbot\",\n",
    "    vocab_size=16000,\n",
    "    character_coverage=1.0,\n",
    "    model_type=\"bpe\",\n",
    "    max_sentence_length=999999,\n",
    "    bos_id=1,  # <s> (Beginning of Sentence) ÏÑ§Ï†ï\n",
    "    eos_id=2,  # </s> (End of Sentence) ÏÑ§Ï†ï\n",
    "    pad_id=0,  # Padding ID ÏÑ§Ï†ï\n",
    "    unk_id=3   # Unknown Token ID ÏÑ§Ï†ï\n",
    ")\n",
    "\n",
    "#ÌïôÏäµ ÏãúÌÇ® ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º Î∂àÎü¨ÏôÄ ÌÖåÏä§Ìä∏\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spm_korean_chatbot.model\")\n",
    "\n",
    "# ÏòàÏ†ú Î¨∏Ïû•\n",
    "sentence = \"ÎÇòÎäî ÏÑºÌÖêÏä§ÌîºÏä§Î°ú ÌååÏù¥ÌÜ†ÏπòÎ•º Î∞∞Ïö∞Í≥† ÏûàÏñ¥Ïöî\"\n",
    "\n",
    "sentence = preprocess_sentence(sentence)\n",
    "print(\"Ï†ÑÏ≤òÎ¶¨ ÌõÑÏùò Î¨∏Ïû•:\", sentence)\n",
    "\n",
    "# 1. ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï (subword Îã®ÏúÑÎ°ú Î∂ÑÌï†)\n",
    "tokens = sp.encode(sentence, out_type=str)\n",
    "print(\"Tokenized:\", tokens)\n",
    "\n",
    "# 2. Ïù∏ÏΩîÎî© (ÏÑúÎ∏åÏõåÎìúÎ•º Ï†ïÏàò IDÎ°ú Î≥ÄÌôò)\n",
    "encoded = sp.encode(sentence, out_type=int)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# 3. ÎîîÏΩîÎî© (Ï†ïÏàò ID ‚Üí ÏõêÎ≥∏ Î¨∏Ïû• Î≥µÏõê)\n",
    "decoded = sp.decode(encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50b5b562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÖêÏÑú ÌÅ¨Í∏∞ : torch.Size([40])\n",
      "tensor([    1,  5550, 14827,  3198,   108,     2,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "12Ïãú Îï° !\n",
      "tensor([   1, 4480,  214, 5917,    4,    2,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî .\n",
      "tensor([4480,  214, 5917,    4,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî .\n"
     ]
    }
   ],
   "source": [
    "#2 Dataset Íµ¨ÌòÑÌïòÍ∏∞\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, pairs, sp, max_length=40):\n",
    "        super().__init__()\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        pad_id = sp.pad_id() # 0\n",
    "        bos_id = sp.bos_id() # 1\n",
    "        eos_id = sp.eos_id() # 2\n",
    "\n",
    "        count_filtered = 0\n",
    "\n",
    "        for q_text, a_text in pairs:\n",
    "            # 1) ÌÜ†ÌÅ¨ÎÇòÏù¥Ï¶à\n",
    "            q_ids = sp.EncodeAsIds(q_text)\n",
    "            a_ids = sp.EncodeAsIds(a_text)\n",
    "\n",
    "            # 2) [CLS]/[SEP] Í∞ôÏùÄ Î≥ÑÎèÑ Ïä§ÌéòÏÖú ÌÜ†ÌÅ∞ÏùÑ Ïì∏ ÏàòÎèÑ ÏûàÏúºÎÇò,\n",
    "            q_tokens = [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            # 3) Í∏∏Ïù¥ Ï†úÌïú\n",
    "            if len(q_tokens) > max_length or len(a_tokens) > max_length:\n",
    "                count_filtered += 1\n",
    "                continue\n",
    "\n",
    "            # 4) Í≥†Ï†ï Í∏∏Ïù¥ Ìå®Îî©\n",
    "            q_padding = [pad_id] * (max_length - len(q_tokens))\n",
    "            a_padding = [pad_id] * (max_length - len(a_tokens))\n",
    "            \n",
    "            q_tokens = q_tokens + q_padding\n",
    "            a_tokens = a_tokens + a_padding\n",
    "\n",
    "            # 5) ÎîîÏΩîÎçî ÏûÖÎ†•(dec_input): a_tokens[:-1], ÌÉÄÍ≤ü(outputs): a_tokens[1:]\n",
    "            #    (teacher forcingÏö©)\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target\n",
    "\n",
    "\n",
    "dataset = ChatbotDataset(pairs, sp, max_length=40)\n",
    "\n",
    "\n",
    "# Decoding Í≥ºÏ†ïÏóêÏÑú start, end ÌÜ†ÌÅ∞ÏùÄ ÏÉùÎüâÌïòÎãà Ïûò Ï∞∏Í≥† startÎäî1, endÎäî 2Ïùò Ïù∏Îç±Ïä§\n",
    "for encoder_input, decoder_input, decoder_label  in dataset:\n",
    "    print(\"ÌÖêÏÑú ÌÅ¨Í∏∞ :\",encoder_input.size())\n",
    "    print(encoder_input)\n",
    "    print(sp.decode(encoder_input.tolist()))\n",
    "    print(decoder_input)\n",
    "    print(sp.decode(decoder_input.tolist()))\n",
    "    print(decoder_label)\n",
    "    print(sp.decode(decoder_label.tolist()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b07f2074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 40])\n",
      "torch.Size([16, 39])\n",
      "torch.Size([16, 39])\n"
     ]
    }
   ],
   "source": [
    "#3 DataLoader Íµ¨ÏÑ±ÌïòÍ∏∞\n",
    "dataloader = DataLoader(dataset,batch_size=16,shuffle=True)\n",
    "\n",
    "for encoder_input, decoder_input, decoder_label in dataloader:\n",
    "    print(encoder_input.size())\n",
    "    print(decoder_input.size())\n",
    "    print(decoder_label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5c13e",
   "metadata": {},
   "source": [
    "STEP4. Î™®Îç∏ Íµ¨ÏÑ±ÌïòÍ∏∞ (Ìä∏ÎûúÏä§Ìè¨Î®∏ Î™®Îç∏ Íµ¨ÌòÑ)\n",
    "- ÏúÑ Ïã§Ïäµ ÎÇ¥Ïö©ÏùÑ Ï∞∏Í≥†ÌïòÏó¨ Ìä∏ÎûúÏä§Ìè¨Î®∏ Î™®Îç∏ÏùÑ Íµ¨ÌòÑÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f972e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "815ca800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) QÏôÄ KÏùò ÎÇ¥Ï†ÅÏùÑ ÌÜµÌï¥ score(Ïú†ÏÇ¨ÎèÑ) Í≥ÑÏÇ∞\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul Í≤∞Í≥º shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depthÏóê Îî∞Îùº Ï†ïÍ∑úÌôî\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) ÎßàÏä§ÌÅ¨Í∞Ä Ï£ºÏñ¥Ï°åÎã§Î©¥ -1e9(ÏïÑÏ£º ÏûëÏùÄ Í∞í)Î•º ÎçîÌï¥ ÏÜåÌîÑÌä∏Îß•Ïä§ÏóêÏÑú Ï†úÏô∏ÏãúÌÇ§ÎèÑÎ°ù Ìï®\n",
    "    if mask is not None:\n",
    "        # ÌÖêÏÑúÌîåÎ°úÏö∞: logits += (mask * -1e9)\n",
    "        # ÌååÏù¥ÌÜ†Ïπò ÎèôÏùº Ï†ÅÏö©\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) ÏÜåÌîÑÌä∏Îß•Ïä§ Í≥ÑÏÇ∞Ìï¥ attention weights ÏÉùÏÑ±\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weightsÏôÄ valueÏùò ÎÇ¥Ï†Å\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3975ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_modelÏùÄ num_headsÎ°ú ÎÇòÎàÑÏñ¥Îñ®Ïñ¥Ï†∏Ïïº Ìï®\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú DenseÎäî nn.LinearÎ°ú ÎåÄÏùë\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) ÌòïÌÉúÎ°ú Î≥ÄÌôò\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) Îì±ÏúºÎ°ú broadcast Í∞ÄÎä•ÌïòÎèÑÎ°ù Íµ¨ÏÑ±\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, VÏóê Í∞ÅÍ∞Å Linear Ï†ÅÏö©\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head Î∂ÑÌï†\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # Ïä§ÏºÄÏùºÎìú Îã∑ ÌîÑÎ°úÎçïÌä∏ Ïñ¥ÌÖêÏÖò\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # Îã§Ïãú (batch_size, seq_len, d_model)Î°ú Ìï©ÏπòÍ∏∞\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # ÏµúÏ¢Ö Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "377bf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 ÏúÑÏπòÎ•º Ï∞æÏïÑ floatÌòï 1Î°ú Î≥ÄÌôò\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "044a352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) ÌÅ¨Í∏∞Ïùò ÌïòÏÇºÍ∞Å ÌñâÎ†¨(tril) ÏÉùÏÑ± ÌõÑ 1ÏóêÏÑú ÎπºÏÑú\n",
    "    # ÏÉÅÏÇºÍ∞ÅÏù¥ 1, ÌïòÏÇºÍ∞Å(ÏûêÍ∏∞ ÏûêÏã† Ìè¨Ìï®)Ïù¥ 0Ïù¥ ÎêòÎèÑÎ°ù ÏÑ§Ï†ï\n",
    "    # => ÎØ∏Îûò ÌÜ†ÌÅ∞(ÏûêÏã† Ïù∏Îç±Ïä§Î≥¥Îã§ ÌÅ∞ ÏúÑÏπò) ÎßàÏä§ÌÇπ\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # Ìå®Îî© ÎßàÏä§ÌÅ¨ ÏÉùÏÑ± (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead ÎßàÏä§ÌÅ¨ÏôÄ Ìå®Îî© ÎßàÏä§ÌÅ¨Î•º Ìï©ÏÑ± (Îëò Ï§ë ÌïòÎÇòÎùºÎèÑ 1Ïù¥Î©¥ ÎßàÏä§ÌÇπ)\n",
    "    # ÏµúÏ¢Ö shapeÏùÄ Î∏åÎ°úÎìúÏ∫êÏä§ÌåÖÏúºÎ°ú (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f09b5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # Ïù¥Ï†ÑÏóê Íµ¨ÌòÑÌïú MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # ÌîºÎìúÌè¨ÏõåÎìú Î∂ÄÎ∂Ñ (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) Î©ÄÌã∞ Ìó§Îìú Ïñ¥ÌÖêÏÖò (ÏÖÄÌîÑ Ïñ¥ÌÖêÏÖò)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # ÏûîÏ∞® Ïó∞Í≤∞ + LayerNorm\n",
    "\n",
    "        # (2) ÌîºÎìúÌè¨ÏõåÎìú Ïã†Í≤ΩÎßù\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # ÏûîÏ∞® Ïó∞Í≤∞ + LayerNorm\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc7aaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) Ìè¨ÏßÄÏÖîÎÑê Ïù∏ÏΩîÎî©\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer ÏåìÍ∏∞\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) ÏûÑÎ≤†Îî© & sqrt(d_model)Î°ú Ïä§ÏºÄÏùºÎßÅ\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) Ìè¨ÏßÄÏÖîÎÑê Ïù∏ÏΩîÎî© Ï†ÅÏö© + ÎìúÎ°≠ÏïÑÏõÉ\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layersÎßåÌÅº ÏåìÏïÑÏò¨Î¶∞ EncoderLayer ÌÜµÍ≥º\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91753313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # Ï≤´ Î≤àÏß∏ ÏÑúÎ∏å Î†àÏù¥Ïñ¥ (ÎîîÏΩîÎçî ÎÇ¥Î∂Ä ÏÖÄÌîÑ Ïñ¥ÌÖêÏÖò)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # Îëê Î≤àÏß∏ ÏÑúÎ∏å Î†àÏù¥Ïñ¥ (Ïù∏ÏΩîÎçî-ÎîîÏΩîÎçî Ïñ¥ÌÖêÏÖò)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # ÏÑ∏ Î≤àÏß∏ ÏÑúÎ∏å Î†àÏù¥Ïñ¥ (ÌîºÎìúÌè¨ÏõåÎìú ÎÑ§Ìä∏ÏõåÌÅ¨)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # ÎìúÎ°≠ÏïÑÏõÉ\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) ÏÖÄÌîÑ Ïñ¥ÌÖêÏÖò (ÎîîÏΩîÎçî ÎÇ¥Î∂Ä)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # ÏûîÏ∞® Ïó∞Í≤∞ + LayerNorm\n",
    "\n",
    "        # 2) Ïù∏ÏΩîÎçî-ÎîîÏΩîÎçî Ïñ¥ÌÖêÏÖò\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # ÏûîÏ∞® Ïó∞Í≤∞ + LayerNorm\n",
    "\n",
    "        # 3) ÌîºÎìúÌè¨ÏõåÎìú (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # ÏûîÏ∞® Ïó∞Í≤∞ + LayerNorm\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cf42f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) Ìè¨ÏßÄÏÖîÎÑê Ïù∏ÏΩîÎî©\n",
    "        # Ïã§Ï†ú ÌïôÏäµ ÏãúÏóêÎäî ÏµúÎåÄ ÏãúÌÄÄÏä§ Í∏∏Ïù¥Ïóê ÎßûÏ∂îÏñ¥ Ïì∞Í∏∞ÎèÑ Ìï®\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer ÏåìÍ∏∞\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) ÏûÑÎ≤†Îî© + sqrt(d_model)Î°ú Ïä§ÏºÄÏùºÎßÅ\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) Ìè¨ÏßÄÏÖîÎÑê Ïù∏ÏΩîÎî© + ÎìúÎ°≠ÏïÑÏõÉ\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layersÎßåÌÅº ÏåìÏù∏ DecoderLayer ÌÜµÍ≥º\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b259d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÏïûÏÑú ÏÇ¨Ïö©Ìïú Ïù∏ÏΩîÎçî Ï∏µ, ÎîîÏΩîÎçî Ï∏µ Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ìä∏ÎûúÏä§Ìè¨Î®∏ Ìï®Ïàò Ï†ïÏùò\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # Ïù∏ÏΩîÎçî/ÎîîÏΩîÎçî Ï∏µ Ïàò\n",
    "                 units,           # feed-forward ÎÑ§Ìä∏ÏõåÌÅ¨Ïùò Ï§ëÍ∞Ñ Ï∞®Ïõê(ff_dim)\n",
    "                 d_model,         # ÏûÑÎ≤†Îî© Î∞è ÎÇ¥Î∂Ä ÌëúÌòÑ Ï∞®Ïõê\n",
    "                 num_heads,       # Î©ÄÌã∞Ìó§Îìú Ïñ¥ÌÖêÏÖòÏùò Ìó§Îìú Ïàò\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # Ïù∏ÏΩîÎçî\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # ÎîîÏΩîÎçî\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # ÏµúÏ¢Ö Ï∂úÎ†•Ï∏µ: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # Ï∞∏Í≥†: ÌÖêÏÑúÌîåÎ°úÏö∞ ÏΩîÎìúÏùò `name=\"transformer\"`Îäî ÌååÏù¥ÌÜ†ÏπòÏóêÏÑ† Î≥¥ÌÜµ ÏÇ¨Ïö© Ïïà Ìï®\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) Ïù∏ÏΩîÎçî Ìå®Îî© ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) ÎîîÏΩîÎçî look-ahead + Ìå®Îî© ÎßàÏä§ÌÅ¨\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) ÎîîÏΩîÎçîÏóêÏÑú Ïù∏ÏΩîÎçî Ï∂úÎ†• Ï™ΩÏùÑ ÎßàÏä§ÌÇπÌï† Îïå Ïì∏ Ìå®Îî© ÎßàÏä§ÌÅ¨\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) Ïù∏ÏΩîÎçî ÏàòÌñâ\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) ÎîîÏΩîÎçî ÏàòÌñâ\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) ÏµúÏ¢Ö Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5afd2b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(16000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-5): 6 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(16000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-5): 6 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=512, out_features=16000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1 Î™®Îç∏ ÏÉùÏÑ±\n",
    "# Ïòà: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "NUM_LAYERS = 6     # Ïù∏ÏΩîÎçî/ÎîîÏΩîÎçî Ï∏µ Ïàò\n",
    "D_MODEL = 512      # ÏûÑÎ≤†Îî© Î∞è ÎÇ¥Î∂Ä ÌëúÌòÑ Ï∞®Ïõê\n",
    "NUM_HEADS = 8      # Î©ÄÌã∞Ìó§Îìú Ïñ¥ÌÖêÏÖòÏóêÏÑúÏùò Ìó§Îìú Ïàò\n",
    "UNITS = 2048       # ÌîºÎìúÌè¨ÏõåÎìú Ïã†Í≤ΩÎßùÏùò ÏùÄÎãâ Ï∞®Ïõê\n",
    "DROPOUT = 0.1      # ÎìúÎ°≠ÏïÑÏõÉ ÎπÑÏú®\n",
    "VOCAB_SIZE = 16000 # Îã®Ïñ¥ ÏßëÌï© ÌÅ¨Í∏∞(ÏòàÏãú)\n",
    "\n",
    "# Î™®Îç∏ ÏÉùÏÑ±\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "#2 ÏÜêÏã§Ìï®Ïàò\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())\n",
    "\n",
    "\n",
    "#3 Ïª§Ïä§ÌÖÄ Îêú ÌïôÏäµÎ•†\n",
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        # stepÏùÄ 0Î∂ÄÌÑ∞ ÏãúÏûëÌïòÎØÄÎ°ú +1Î°ú Î≥¥Ï†ï\n",
    "        step = step + 1\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda\n",
    "\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # Ï¥ù ÌïôÏäµ Ïä§ÌÖù\n",
    "\n",
    "# ÌïôÏäµÎ•† Ïä§ÏºÄÏ§Ñ ÏãúÍ∞ÅÌôî\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# Í∑∏ÎûòÌîÑ Ï∂úÎ†•\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27bb88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Î™®Îç∏ Ïª¥ÌååÏùº\n",
    "# Optimizer Ï†ïÏùò\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Scheduler Ï†ïÏùò\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=4000))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5cfe7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 ÌõàÎ†®ÌïòÍ∏∞\n",
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Î™®Îç∏ Ìè¨ÏõåÎìú Ìå®Ïä§\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss Í≥ÑÏÇ∞ (Ìå®Îî© ÌÜ†ÌÅ∞ Î¨¥Ïãú)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) ÌïÑÏöî\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            # ÏùºÏ†ï Ïä§ÌÖùÎßàÎã§ Î°úÍ∑∏ Ï∂úÎ†•\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d2ac68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.9195, Acc: 0.0000\n",
      "[Epoch 1, Step 100] Loss: 9.8184, Acc: 0.0000\n",
      "[Epoch 1, Step 200] Loss: 9.6604, Acc: 0.0000\n",
      "[Epoch 1, Step 300] Loss: 9.7175, Acc: 0.0000\n",
      "[Epoch 1, Step 400] Loss: 9.6100, Acc: 0.0000\n",
      "[Epoch 1, Step 500] Loss: 9.4418, Acc: 0.0098\n",
      "[Epoch 1, Step 600] Loss: 9.2267, Acc: 0.1042\n",
      "[Epoch 1, Step 700] Loss: 8.9901, Acc: 0.1731\n",
      "Epoch 1 Completed - Avg Loss: 9.5559, Avg Acc: 0.0313\n",
      "[Epoch 2, Step 0] Loss: 8.8204, Acc: 0.2766\n",
      "[Epoch 2, Step 100] Loss: 8.8293, Acc: 0.2788\n",
      "[Epoch 2, Step 200] Loss: 8.5408, Acc: 0.2710\n",
      "[Epoch 2, Step 300] Loss: 8.1197, Acc: 0.3053\n",
      "[Epoch 2, Step 400] Loss: 7.8217, Acc: 0.3297\n",
      "[Epoch 2, Step 500] Loss: 7.6743, Acc: 0.3333\n",
      "[Epoch 2, Step 600] Loss: 7.4623, Acc: 0.3441\n",
      "[Epoch 2, Step 700] Loss: 7.2247, Acc: 0.3371\n",
      "Epoch 2 Completed - Avg Loss: 8.0877, Avg Acc: 0.2996\n",
      "[Epoch 3, Step 0] Loss: 7.2158, Acc: 0.3068\n",
      "[Epoch 3, Step 100] Loss: 7.2905, Acc: 0.3068\n",
      "[Epoch 3, Step 200] Loss: 7.4904, Acc: 0.2941\n",
      "[Epoch 3, Step 300] Loss: 7.1626, Acc: 0.3226\n",
      "[Epoch 3, Step 400] Loss: 7.4078, Acc: 0.2963\n",
      "[Epoch 3, Step 500] Loss: 7.2643, Acc: 0.3200\n",
      "[Epoch 3, Step 600] Loss: 6.9148, Acc: 0.3400\n",
      "[Epoch 3, Step 700] Loss: 7.3729, Acc: 0.2857\n",
      "Epoch 3 Completed - Avg Loss: 7.1391, Avg Acc: 0.3245\n",
      "[Epoch 4, Step 0] Loss: 6.9378, Acc: 0.3368\n",
      "[Epoch 4, Step 100] Loss: 6.8955, Acc: 0.3404\n",
      "[Epoch 4, Step 200] Loss: 6.8314, Acc: 0.3516\n",
      "[Epoch 4, Step 300] Loss: 6.4399, Acc: 0.3797\n",
      "[Epoch 4, Step 400] Loss: 7.4019, Acc: 0.2703\n",
      "[Epoch 4, Step 500] Loss: 6.8826, Acc: 0.3125\n",
      "[Epoch 4, Step 600] Loss: 6.9027, Acc: 0.3200\n",
      "[Epoch 4, Step 700] Loss: 7.1824, Acc: 0.2883\n",
      "Epoch 4 Completed - Avg Loss: 6.8657, Avg Acc: 0.3257\n",
      "[Epoch 5, Step 0] Loss: 6.4894, Acc: 0.3647\n",
      "[Epoch 5, Step 100] Loss: 7.2091, Acc: 0.2895\n",
      "[Epoch 5, Step 200] Loss: 6.5069, Acc: 0.3478\n",
      "[Epoch 5, Step 300] Loss: 6.7524, Acc: 0.3030\n",
      "[Epoch 5, Step 400] Loss: 6.8000, Acc: 0.3000\n",
      "[Epoch 5, Step 500] Loss: 6.3401, Acc: 0.3605\n",
      "[Epoch 5, Step 600] Loss: 6.8568, Acc: 0.3137\n",
      "[Epoch 5, Step 700] Loss: 6.4914, Acc: 0.3441\n",
      "Epoch 5 Completed - Avg Loss: 6.6991, Avg Acc: 0.3254\n",
      "[Epoch 6, Step 0] Loss: 6.3827, Acc: 0.3505\n",
      "[Epoch 6, Step 100] Loss: 6.4240, Acc: 0.3614\n",
      "[Epoch 6, Step 200] Loss: 6.4287, Acc: 0.3478\n",
      "[Epoch 6, Step 300] Loss: 7.0114, Acc: 0.3000\n",
      "[Epoch 6, Step 400] Loss: 6.5910, Acc: 0.3200\n",
      "[Epoch 6, Step 500] Loss: 6.5217, Acc: 0.3222\n",
      "[Epoch 6, Step 600] Loss: 7.1962, Acc: 0.2540\n",
      "[Epoch 6, Step 700] Loss: 5.9984, Acc: 0.3678\n",
      "Epoch 6 Completed - Avg Loss: 6.5595, Avg Acc: 0.3256\n",
      "[Epoch 7, Step 0] Loss: 6.6647, Acc: 0.3048\n",
      "[Epoch 7, Step 100] Loss: 6.3757, Acc: 0.3529\n",
      "[Epoch 7, Step 200] Loss: 6.4035, Acc: 0.3298\n",
      "[Epoch 7, Step 300] Loss: 6.4179, Acc: 0.3069\n",
      "[Epoch 7, Step 400] Loss: 6.4700, Acc: 0.3299\n",
      "[Epoch 7, Step 500] Loss: 6.0912, Acc: 0.3556\n",
      "[Epoch 7, Step 600] Loss: 6.3473, Acc: 0.3478\n",
      "[Epoch 7, Step 700] Loss: 6.3430, Acc: 0.3265\n",
      "Epoch 7 Completed - Avg Loss: 6.4457, Avg Acc: 0.3256\n",
      "[Epoch 8, Step 0] Loss: 5.9248, Acc: 0.3875\n",
      "[Epoch 8, Step 100] Loss: 6.4721, Acc: 0.3368\n",
      "[Epoch 8, Step 200] Loss: 6.2263, Acc: 0.3516\n",
      "[Epoch 8, Step 300] Loss: 6.2972, Acc: 0.3125\n",
      "[Epoch 8, Step 400] Loss: 6.0452, Acc: 0.3441\n",
      "[Epoch 8, Step 500] Loss: 6.1277, Acc: 0.3333\n",
      "[Epoch 8, Step 600] Loss: 6.5134, Acc: 0.2991\n",
      "[Epoch 8, Step 700] Loss: 6.4526, Acc: 0.3028\n",
      "Epoch 8 Completed - Avg Loss: 6.3532, Avg Acc: 0.3263\n",
      "[Epoch 9, Step 0] Loss: 6.3288, Acc: 0.3173\n",
      "[Epoch 9, Step 100] Loss: 6.3769, Acc: 0.3333\n",
      "[Epoch 9, Step 200] Loss: 6.5254, Acc: 0.3152\n",
      "[Epoch 9, Step 300] Loss: 6.3255, Acc: 0.3182\n",
      "[Epoch 9, Step 400] Loss: 5.9848, Acc: 0.3548\n",
      "[Epoch 9, Step 500] Loss: 6.3416, Acc: 0.3158\n",
      "[Epoch 9, Step 600] Loss: 5.8630, Acc: 0.3605\n",
      "[Epoch 9, Step 700] Loss: 6.3719, Acc: 0.3232\n",
      "Epoch 9 Completed - Avg Loss: 6.2736, Avg Acc: 0.3277\n",
      "[Epoch 10, Step 0] Loss: 6.4941, Acc: 0.2844\n",
      "[Epoch 10, Step 100] Loss: 6.1418, Acc: 0.3152\n",
      "[Epoch 10, Step 200] Loss: 6.4736, Acc: 0.3048\n",
      "[Epoch 10, Step 300] Loss: 6.1150, Acc: 0.3448\n",
      "[Epoch 10, Step 400] Loss: 6.0475, Acc: 0.3299\n",
      "[Epoch 10, Step 500] Loss: 6.2338, Acc: 0.3333\n",
      "[Epoch 10, Step 600] Loss: 5.8392, Acc: 0.3297\n",
      "[Epoch 10, Step 700] Loss: 6.3127, Acc: 0.3229\n",
      "Epoch 10 Completed - Avg Loss: 6.2053, Avg Acc: 0.3284\n",
      "[Epoch 11, Step 0] Loss: 6.1839, Acc: 0.3168\n",
      "[Epoch 11, Step 100] Loss: 6.3462, Acc: 0.3298\n",
      "[Epoch 11, Step 200] Loss: 5.8531, Acc: 0.3261\n",
      "[Epoch 11, Step 300] Loss: 5.9498, Acc: 0.3415\n",
      "[Epoch 11, Step 400] Loss: 6.1642, Acc: 0.3333\n",
      "[Epoch 11, Step 500] Loss: 6.6411, Acc: 0.3019\n",
      "[Epoch 11, Step 600] Loss: 5.8793, Acc: 0.3511\n",
      "[Epoch 11, Step 700] Loss: 5.8850, Acc: 0.3441\n",
      "Epoch 11 Completed - Avg Loss: 6.1433, Avg Acc: 0.3287\n",
      "[Epoch 12, Step 0] Loss: 6.2713, Acc: 0.3077\n",
      "[Epoch 12, Step 100] Loss: 5.9567, Acc: 0.3708\n",
      "[Epoch 12, Step 200] Loss: 6.3810, Acc: 0.2920\n",
      "[Epoch 12, Step 300] Loss: 6.3236, Acc: 0.2830\n",
      "[Epoch 12, Step 400] Loss: 6.0823, Acc: 0.3069\n",
      "[Epoch 12, Step 500] Loss: 6.3672, Acc: 0.3010\n",
      "[Epoch 12, Step 600] Loss: 6.0050, Acc: 0.3441\n",
      "[Epoch 12, Step 700] Loss: 6.1464, Acc: 0.3093\n",
      "Epoch 12 Completed - Avg Loss: 6.0903, Avg Acc: 0.3290\n",
      "[Epoch 13, Step 0] Loss: 5.7905, Acc: 0.3571\n",
      "[Epoch 13, Step 100] Loss: 6.0425, Acc: 0.3200\n",
      "[Epoch 13, Step 200] Loss: 5.9854, Acc: 0.3263\n",
      "[Epoch 13, Step 300] Loss: 5.8195, Acc: 0.3333\n",
      "[Epoch 13, Step 400] Loss: 5.8644, Acc: 0.3596\n",
      "[Epoch 13, Step 500] Loss: 6.3303, Acc: 0.2963\n",
      "[Epoch 13, Step 600] Loss: 5.9466, Acc: 0.3448\n",
      "[Epoch 13, Step 700] Loss: 6.5133, Acc: 0.2929\n",
      "Epoch 13 Completed - Avg Loss: 6.0390, Avg Acc: 0.3296\n",
      "[Epoch 14, Step 0] Loss: 6.2914, Acc: 0.3173\n",
      "[Epoch 14, Step 100] Loss: 6.5316, Acc: 0.2759\n",
      "[Epoch 14, Step 200] Loss: 6.5871, Acc: 0.2941\n",
      "[Epoch 14, Step 300] Loss: 5.9471, Acc: 0.3232\n",
      "[Epoch 14, Step 400] Loss: 5.8475, Acc: 0.3263\n",
      "[Epoch 14, Step 500] Loss: 5.8484, Acc: 0.3441\n",
      "[Epoch 14, Step 600] Loss: 5.9912, Acc: 0.3678\n",
      "[Epoch 14, Step 700] Loss: 6.1265, Acc: 0.3107\n",
      "Epoch 14 Completed - Avg Loss: 5.9937, Avg Acc: 0.3305\n",
      "[Epoch 15, Step 0] Loss: 6.1815, Acc: 0.3173\n",
      "[Epoch 15, Step 100] Loss: 5.7594, Acc: 0.3404\n",
      "[Epoch 15, Step 200] Loss: 6.1208, Acc: 0.3069\n",
      "[Epoch 15, Step 300] Loss: 6.2561, Acc: 0.3366\n",
      "[Epoch 15, Step 400] Loss: 5.7617, Acc: 0.3367\n",
      "[Epoch 15, Step 500] Loss: 5.7126, Acc: 0.3626\n",
      "[Epoch 15, Step 600] Loss: 6.0969, Acc: 0.2957\n",
      "[Epoch 15, Step 700] Loss: 5.5248, Acc: 0.3587\n",
      "Epoch 15 Completed - Avg Loss: 5.9555, Avg Acc: 0.3319\n",
      "[Epoch 16, Step 0] Loss: 6.1895, Acc: 0.2973\n",
      "[Epoch 16, Step 100] Loss: 5.9448, Acc: 0.2921\n",
      "[Epoch 16, Step 200] Loss: 6.1630, Acc: 0.3232\n",
      "[Epoch 16, Step 300] Loss: 5.8922, Acc: 0.3333\n",
      "[Epoch 16, Step 400] Loss: 6.2408, Acc: 0.2970\n",
      "[Epoch 16, Step 500] Loss: 5.6766, Acc: 0.3448\n",
      "[Epoch 16, Step 600] Loss: 6.1591, Acc: 0.3061\n",
      "[Epoch 16, Step 700] Loss: 6.1220, Acc: 0.2909\n",
      "Epoch 16 Completed - Avg Loss: 5.9157, Avg Acc: 0.3333\n",
      "[Epoch 17, Step 0] Loss: 5.9818, Acc: 0.3448\n",
      "[Epoch 17, Step 100] Loss: 5.9071, Acc: 0.3061\n",
      "[Epoch 17, Step 200] Loss: 5.3633, Acc: 0.4000\n",
      "[Epoch 17, Step 300] Loss: 6.1998, Acc: 0.2952\n",
      "[Epoch 17, Step 400] Loss: 5.7172, Acc: 0.3548\n",
      "[Epoch 17, Step 500] Loss: 5.9196, Acc: 0.3478\n",
      "[Epoch 17, Step 600] Loss: 5.3407, Acc: 0.3929\n",
      "[Epoch 17, Step 700] Loss: 5.6885, Acc: 0.3178\n",
      "Epoch 17 Completed - Avg Loss: 5.8817, Avg Acc: 0.3346\n",
      "[Epoch 18, Step 0] Loss: 6.0372, Acc: 0.3163\n",
      "[Epoch 18, Step 100] Loss: 5.9474, Acc: 0.3238\n",
      "[Epoch 18, Step 200] Loss: 6.0182, Acc: 0.3168\n",
      "[Epoch 18, Step 300] Loss: 5.5820, Acc: 0.3400\n",
      "[Epoch 18, Step 400] Loss: 5.6836, Acc: 0.3168\n",
      "[Epoch 18, Step 500] Loss: 5.7720, Acc: 0.3371\n",
      "[Epoch 18, Step 600] Loss: 6.0133, Acc: 0.3229\n",
      "[Epoch 18, Step 700] Loss: 6.0665, Acc: 0.3173\n",
      "Epoch 18 Completed - Avg Loss: 5.8520, Avg Acc: 0.3349\n",
      "[Epoch 19, Step 0] Loss: 6.0545, Acc: 0.3438\n",
      "[Epoch 19, Step 100] Loss: 5.7720, Acc: 0.3478\n",
      "[Epoch 19, Step 200] Loss: 5.6386, Acc: 0.3478\n",
      "[Epoch 19, Step 300] Loss: 6.1399, Acc: 0.3061\n",
      "[Epoch 19, Step 400] Loss: 6.4908, Acc: 0.2883\n",
      "[Epoch 19, Step 500] Loss: 6.1618, Acc: 0.2816\n",
      "[Epoch 19, Step 600] Loss: 5.5498, Acc: 0.3494\n",
      "[Epoch 19, Step 700] Loss: 6.1060, Acc: 0.3137\n",
      "Epoch 19 Completed - Avg Loss: 5.8207, Avg Acc: 0.3354\n",
      "[Epoch 20, Step 0] Loss: 5.9552, Acc: 0.3019\n",
      "[Epoch 20, Step 100] Loss: 5.6465, Acc: 0.3368\n",
      "[Epoch 20, Step 200] Loss: 5.7497, Acc: 0.3474\n",
      "[Epoch 20, Step 300] Loss: 6.1970, Acc: 0.3039\n",
      "[Epoch 20, Step 400] Loss: 5.7869, Acc: 0.3048\n",
      "[Epoch 20, Step 500] Loss: 5.9045, Acc: 0.3438\n",
      "[Epoch 20, Step 600] Loss: 5.7309, Acc: 0.3448\n",
      "[Epoch 20, Step 700] Loss: 5.6985, Acc: 0.3222\n",
      "Epoch 20 Completed - Avg Loss: 5.7948, Avg Acc: 0.3357\n",
      "[Epoch 21, Step 0] Loss: 5.7411, Acc: 0.3208\n",
      "[Epoch 21, Step 100] Loss: 5.8678, Acc: 0.3125\n",
      "[Epoch 21, Step 200] Loss: 6.0200, Acc: 0.2885\n",
      "[Epoch 21, Step 300] Loss: 5.5232, Acc: 0.3678\n",
      "[Epoch 21, Step 400] Loss: 5.7469, Acc: 0.3431\n",
      "[Epoch 21, Step 500] Loss: 5.5040, Acc: 0.3579\n",
      "[Epoch 21, Step 600] Loss: 5.4301, Acc: 0.3556\n",
      "[Epoch 21, Step 700] Loss: 5.9027, Acc: 0.3301\n",
      "Epoch 21 Completed - Avg Loss: 5.7707, Avg Acc: 0.3360\n",
      "[Epoch 22, Step 0] Loss: 5.9177, Acc: 0.3438\n",
      "[Epoch 22, Step 100] Loss: 5.7561, Acc: 0.3626\n",
      "[Epoch 22, Step 200] Loss: 5.5587, Acc: 0.3810\n",
      "[Epoch 22, Step 300] Loss: 5.9024, Acc: 0.3241\n",
      "[Epoch 22, Step 400] Loss: 5.4117, Acc: 0.3723\n",
      "[Epoch 22, Step 500] Loss: 6.1861, Acc: 0.3019\n",
      "[Epoch 22, Step 600] Loss: 5.6814, Acc: 0.3269\n",
      "[Epoch 22, Step 700] Loss: 5.5357, Acc: 0.3438\n",
      "Epoch 22 Completed - Avg Loss: 5.7446, Avg Acc: 0.3374\n",
      "[Epoch 23, Step 0] Loss: 5.7336, Acc: 0.3465\n",
      "[Epoch 23, Step 100] Loss: 5.1623, Acc: 0.4070\n",
      "[Epoch 23, Step 200] Loss: 5.3697, Acc: 0.3596\n",
      "[Epoch 23, Step 300] Loss: 5.6898, Acc: 0.3750\n",
      "[Epoch 23, Step 400] Loss: 6.4968, Acc: 0.2566\n",
      "[Epoch 23, Step 500] Loss: 5.8195, Acc: 0.3267\n",
      "[Epoch 23, Step 600] Loss: 5.6483, Acc: 0.3474\n",
      "[Epoch 23, Step 700] Loss: 5.3970, Acc: 0.3810\n",
      "Epoch 23 Completed - Avg Loss: 5.7265, Avg Acc: 0.3378\n",
      "[Epoch 24, Step 0] Loss: 5.8128, Acc: 0.3298\n",
      "[Epoch 24, Step 100] Loss: 5.6047, Acc: 0.3511\n",
      "[Epoch 24, Step 200] Loss: 5.3261, Acc: 0.3571\n",
      "[Epoch 24, Step 300] Loss: 5.6746, Acc: 0.3333\n",
      "[Epoch 24, Step 400] Loss: 5.0128, Acc: 0.3647\n",
      "[Epoch 24, Step 500] Loss: 5.7938, Acc: 0.3438\n",
      "[Epoch 24, Step 600] Loss: 5.8454, Acc: 0.3367\n",
      "[Epoch 24, Step 700] Loss: 5.4432, Acc: 0.3837\n",
      "Epoch 24 Completed - Avg Loss: 5.7042, Avg Acc: 0.3390\n",
      "[Epoch 25, Step 0] Loss: 5.7643, Acc: 0.3137\n",
      "[Epoch 25, Step 100] Loss: 5.4209, Acc: 0.3678\n",
      "[Epoch 25, Step 200] Loss: 5.6406, Acc: 0.3370\n",
      "[Epoch 25, Step 300] Loss: 5.1553, Acc: 0.3810\n",
      "[Epoch 25, Step 400] Loss: 5.7423, Acc: 0.3441\n",
      "[Epoch 25, Step 500] Loss: 5.3339, Acc: 0.3778\n",
      "[Epoch 25, Step 600] Loss: 5.7264, Acc: 0.3474\n",
      "[Epoch 25, Step 700] Loss: 5.7168, Acc: 0.3402\n",
      "Epoch 25 Completed - Avg Loss: 5.6863, Avg Acc: 0.3400\n",
      "[Epoch 26, Step 0] Loss: 5.9472, Acc: 0.3028\n",
      "[Epoch 26, Step 100] Loss: 5.3766, Acc: 0.3636\n",
      "[Epoch 26, Step 200] Loss: 5.4149, Acc: 0.3548\n",
      "[Epoch 26, Step 300] Loss: 5.9694, Acc: 0.3232\n",
      "[Epoch 26, Step 400] Loss: 5.8424, Acc: 0.3298\n",
      "[Epoch 26, Step 500] Loss: 5.7692, Acc: 0.3367\n",
      "[Epoch 26, Step 600] Loss: 6.4975, Acc: 0.2970\n",
      "[Epoch 26, Step 700] Loss: 5.5341, Acc: 0.3365\n",
      "Epoch 26 Completed - Avg Loss: 5.6685, Avg Acc: 0.3412\n",
      "[Epoch 27, Step 0] Loss: 5.4265, Acc: 0.3367\n",
      "[Epoch 27, Step 100] Loss: 5.5864, Acc: 0.3333\n",
      "[Epoch 27, Step 200] Loss: 5.4619, Acc: 0.3678\n",
      "[Epoch 27, Step 300] Loss: 5.3623, Acc: 0.3889\n",
      "[Epoch 27, Step 400] Loss: 5.5101, Acc: 0.3404\n",
      "[Epoch 27, Step 500] Loss: 5.7276, Acc: 0.3608\n",
      "[Epoch 27, Step 600] Loss: 5.5413, Acc: 0.3636\n",
      "[Epoch 27, Step 700] Loss: 5.9205, Acc: 0.3263\n",
      "Epoch 27 Completed - Avg Loss: 5.6499, Avg Acc: 0.3420\n",
      "[Epoch 28, Step 0] Loss: 5.6982, Acc: 0.3370\n",
      "[Epoch 28, Step 100] Loss: 5.7310, Acc: 0.3263\n",
      "[Epoch 28, Step 200] Loss: 5.5285, Acc: 0.3563\n",
      "[Epoch 28, Step 300] Loss: 5.6077, Acc: 0.3200\n",
      "[Epoch 28, Step 400] Loss: 5.4397, Acc: 0.3563\n",
      "[Epoch 28, Step 500] Loss: 5.6108, Acc: 0.3444\n",
      "[Epoch 28, Step 600] Loss: 5.3869, Acc: 0.3238\n",
      "[Epoch 28, Step 700] Loss: 5.4820, Acc: 0.3483\n",
      "Epoch 28 Completed - Avg Loss: 5.6362, Avg Acc: 0.3426\n",
      "[Epoch 29, Step 0] Loss: 5.7493, Acc: 0.3469\n",
      "[Epoch 29, Step 100] Loss: 5.2814, Acc: 0.3875\n",
      "[Epoch 29, Step 200] Loss: 5.7830, Acc: 0.3404\n",
      "[Epoch 29, Step 300] Loss: 5.4381, Acc: 0.3579\n",
      "[Epoch 29, Step 400] Loss: 5.5911, Acc: 0.3404\n",
      "[Epoch 29, Step 500] Loss: 6.0851, Acc: 0.2991\n",
      "[Epoch 29, Step 600] Loss: 5.1484, Acc: 0.3855\n",
      "[Epoch 29, Step 700] Loss: 5.3138, Acc: 0.3723\n",
      "Epoch 29 Completed - Avg Loss: 5.6194, Avg Acc: 0.3431\n",
      "[Epoch 30, Step 0] Loss: 5.7149, Acc: 0.3131\n",
      "[Epoch 30, Step 100] Loss: 5.4806, Acc: 0.3137\n",
      "[Epoch 30, Step 200] Loss: 5.5427, Acc: 0.3333\n",
      "[Epoch 30, Step 300] Loss: 6.0461, Acc: 0.3269\n",
      "[Epoch 30, Step 400] Loss: 5.7958, Acc: 0.3333\n",
      "[Epoch 30, Step 500] Loss: 5.6595, Acc: 0.3333\n",
      "[Epoch 30, Step 600] Loss: 4.9609, Acc: 0.3933\n",
      "[Epoch 30, Step 700] Loss: 5.6392, Acc: 0.3333\n",
      "Epoch 30 Completed - Avg Loss: 5.6044, Avg Acc: 0.3434\n",
      "[Epoch 31, Step 0] Loss: 5.4626, Acc: 0.3238\n",
      "[Epoch 31, Step 100] Loss: 5.0083, Acc: 0.4048\n",
      "[Epoch 31, Step 200] Loss: 5.9270, Acc: 0.3299\n",
      "[Epoch 31, Step 300] Loss: 5.6511, Acc: 0.3333\n",
      "[Epoch 31, Step 400] Loss: 5.1866, Acc: 0.3837\n",
      "[Epoch 31, Step 500] Loss: 5.9078, Acc: 0.2913\n",
      "[Epoch 31, Step 600] Loss: 5.7812, Acc: 0.3182\n",
      "[Epoch 31, Step 700] Loss: 5.3632, Acc: 0.3696\n",
      "Epoch 31 Completed - Avg Loss: 5.5926, Avg Acc: 0.3438\n",
      "[Epoch 32, Step 0] Loss: 5.4836, Acc: 0.3736\n",
      "[Epoch 32, Step 100] Loss: 6.0567, Acc: 0.3010\n",
      "[Epoch 32, Step 200] Loss: 5.0156, Acc: 0.3864\n",
      "[Epoch 32, Step 300] Loss: 5.7614, Acc: 0.3131\n",
      "[Epoch 32, Step 400] Loss: 4.8398, Acc: 0.3846\n",
      "[Epoch 32, Step 500] Loss: 5.3740, Acc: 0.3750\n",
      "[Epoch 32, Step 600] Loss: 5.5392, Acc: 0.3488\n",
      "[Epoch 32, Step 700] Loss: 5.6369, Acc: 0.3444\n",
      "Epoch 32 Completed - Avg Loss: 5.5796, Avg Acc: 0.3441\n",
      "[Epoch 33, Step 0] Loss: 5.5878, Acc: 0.3093\n",
      "[Epoch 33, Step 100] Loss: 5.5915, Acc: 0.3400\n",
      "[Epoch 33, Step 200] Loss: 5.8490, Acc: 0.2991\n",
      "[Epoch 33, Step 300] Loss: 5.7251, Acc: 0.3371\n",
      "[Epoch 33, Step 400] Loss: 5.4980, Acc: 0.3542\n",
      "[Epoch 33, Step 500] Loss: 6.0054, Acc: 0.3107\n",
      "[Epoch 33, Step 600] Loss: 5.3908, Acc: 0.3579\n",
      "[Epoch 33, Step 700] Loss: 5.7797, Acc: 0.3333\n",
      "Epoch 33 Completed - Avg Loss: 5.5666, Avg Acc: 0.3448\n",
      "[Epoch 34, Step 0] Loss: 5.9446, Acc: 0.3084\n",
      "[Epoch 34, Step 100] Loss: 5.5865, Acc: 0.3571\n",
      "[Epoch 34, Step 200] Loss: 5.8013, Acc: 0.3261\n",
      "[Epoch 34, Step 300] Loss: 5.7943, Acc: 0.3617\n",
      "[Epoch 34, Step 400] Loss: 5.2267, Acc: 0.4048\n",
      "[Epoch 34, Step 500] Loss: 5.6785, Acc: 0.3444\n",
      "[Epoch 34, Step 600] Loss: 5.5296, Acc: 0.3548\n",
      "[Epoch 34, Step 700] Loss: 5.2738, Acc: 0.3488\n",
      "Epoch 34 Completed - Avg Loss: 5.5552, Avg Acc: 0.3451\n",
      "[Epoch 35, Step 0] Loss: 5.6431, Acc: 0.3564\n",
      "[Epoch 35, Step 100] Loss: 5.2701, Acc: 0.3723\n",
      "[Epoch 35, Step 200] Loss: 5.5148, Acc: 0.3333\n",
      "[Epoch 35, Step 300] Loss: 5.4035, Acc: 0.3656\n",
      "[Epoch 35, Step 400] Loss: 5.0985, Acc: 0.4103\n",
      "[Epoch 35, Step 500] Loss: 5.6494, Acc: 0.3585\n",
      "[Epoch 35, Step 600] Loss: 5.7598, Acc: 0.3084\n",
      "[Epoch 35, Step 700] Loss: 5.2112, Acc: 0.4023\n",
      "Epoch 35 Completed - Avg Loss: 5.5454, Avg Acc: 0.3454\n",
      "[Epoch 36, Step 0] Loss: 5.2820, Acc: 0.3976\n",
      "[Epoch 36, Step 100] Loss: 5.9698, Acc: 0.3010\n",
      "[Epoch 36, Step 200] Loss: 5.4511, Acc: 0.3500\n",
      "[Epoch 36, Step 300] Loss: 5.1877, Acc: 0.3684\n",
      "[Epoch 36, Step 400] Loss: 5.7247, Acc: 0.3217\n",
      "[Epoch 36, Step 500] Loss: 5.5483, Acc: 0.3214\n",
      "[Epoch 36, Step 600] Loss: 5.8136, Acc: 0.3056\n",
      "[Epoch 36, Step 700] Loss: 5.5801, Acc: 0.3441\n",
      "Epoch 36 Completed - Avg Loss: 5.5349, Avg Acc: 0.3454\n",
      "[Epoch 37, Step 0] Loss: 5.4412, Acc: 0.3364\n",
      "[Epoch 37, Step 100] Loss: 5.4727, Acc: 0.3725\n",
      "[Epoch 37, Step 200] Loss: 5.3566, Acc: 0.3600\n",
      "[Epoch 37, Step 300] Loss: 5.8970, Acc: 0.3084\n",
      "[Epoch 37, Step 400] Loss: 6.3339, Acc: 0.2833\n",
      "[Epoch 37, Step 500] Loss: 5.7361, Acc: 0.3000\n",
      "[Epoch 37, Step 600] Loss: 5.4570, Acc: 0.3579\n",
      "[Epoch 37, Step 700] Loss: 5.4034, Acc: 0.3370\n",
      "Epoch 37 Completed - Avg Loss: 5.5249, Avg Acc: 0.3454\n",
      "[Epoch 38, Step 0] Loss: 5.5299, Acc: 0.3301\n",
      "[Epoch 38, Step 100] Loss: 5.5382, Acc: 0.3370\n",
      "[Epoch 38, Step 200] Loss: 5.4398, Acc: 0.3837\n",
      "[Epoch 38, Step 300] Loss: 5.3421, Acc: 0.3505\n",
      "[Epoch 38, Step 400] Loss: 5.8252, Acc: 0.3100\n",
      "[Epoch 38, Step 500] Loss: 5.6001, Acc: 0.3302\n",
      "[Epoch 38, Step 600] Loss: 6.1989, Acc: 0.2750\n",
      "[Epoch 38, Step 700] Loss: 5.3896, Acc: 0.3765\n",
      "Epoch 38 Completed - Avg Loss: 5.5136, Avg Acc: 0.3458\n",
      "[Epoch 39, Step 0] Loss: 5.9830, Acc: 0.3204\n",
      "[Epoch 39, Step 100] Loss: 5.8683, Acc: 0.3204\n",
      "[Epoch 39, Step 200] Loss: 5.1493, Acc: 0.3608\n",
      "[Epoch 39, Step 300] Loss: 5.6945, Acc: 0.3299\n",
      "[Epoch 39, Step 400] Loss: 5.7167, Acc: 0.3153\n",
      "[Epoch 39, Step 500] Loss: 5.2888, Acc: 0.3438\n",
      "[Epoch 39, Step 600] Loss: 5.5411, Acc: 0.3400\n",
      "[Epoch 39, Step 700] Loss: 5.9470, Acc: 0.3226\n",
      "Epoch 39 Completed - Avg Loss: 5.5052, Avg Acc: 0.3461\n",
      "[Epoch 40, Step 0] Loss: 5.3363, Acc: 0.3519\n",
      "[Epoch 40, Step 100] Loss: 5.4388, Acc: 0.3542\n",
      "[Epoch 40, Step 200] Loss: 5.5711, Acc: 0.3684\n",
      "[Epoch 40, Step 300] Loss: 5.4581, Acc: 0.3556\n",
      "[Epoch 40, Step 400] Loss: 5.7216, Acc: 0.3478\n",
      "[Epoch 40, Step 500] Loss: 5.9847, Acc: 0.2832\n",
      "[Epoch 40, Step 600] Loss: 5.6953, Acc: 0.3271\n",
      "[Epoch 40, Step 700] Loss: 5.6007, Acc: 0.3158\n",
      "Epoch 40 Completed - Avg Loss: 5.4955, Avg Acc: 0.3465\n",
      "[Epoch 41, Step 0] Loss: 5.3369, Acc: 0.3438\n",
      "[Epoch 41, Step 100] Loss: 5.3036, Acc: 0.3765\n",
      "[Epoch 41, Step 200] Loss: 5.4970, Acc: 0.3402\n",
      "[Epoch 41, Step 300] Loss: 5.4187, Acc: 0.3267\n",
      "[Epoch 41, Step 400] Loss: 5.0210, Acc: 0.3846\n",
      "[Epoch 41, Step 500] Loss: 5.5043, Acc: 0.3448\n",
      "[Epoch 41, Step 600] Loss: 4.9773, Acc: 0.3529\n",
      "[Epoch 41, Step 700] Loss: 5.7240, Acc: 0.3163\n",
      "Epoch 41 Completed - Avg Loss: 5.4871, Avg Acc: 0.3462\n",
      "[Epoch 42, Step 0] Loss: 5.8180, Acc: 0.3261\n",
      "[Epoch 42, Step 100] Loss: 5.4000, Acc: 0.3300\n",
      "[Epoch 42, Step 200] Loss: 5.1816, Acc: 0.3402\n",
      "[Epoch 42, Step 300] Loss: 5.3077, Acc: 0.3673\n",
      "[Epoch 42, Step 400] Loss: 4.8724, Acc: 0.3953\n",
      "[Epoch 42, Step 500] Loss: 5.0526, Acc: 0.3864\n",
      "[Epoch 42, Step 600] Loss: 5.6187, Acc: 0.3366\n",
      "[Epoch 42, Step 700] Loss: 5.4685, Acc: 0.3333\n",
      "Epoch 42 Completed - Avg Loss: 5.4799, Avg Acc: 0.3465\n",
      "[Epoch 43, Step 0] Loss: 5.5962, Acc: 0.3368\n",
      "[Epoch 43, Step 100] Loss: 5.1863, Acc: 0.3793\n",
      "[Epoch 43, Step 200] Loss: 5.5420, Acc: 0.3300\n",
      "[Epoch 43, Step 300] Loss: 5.3891, Acc: 0.3396\n",
      "[Epoch 43, Step 400] Loss: 4.9856, Acc: 0.3678\n",
      "[Epoch 43, Step 500] Loss: 5.4332, Acc: 0.3400\n",
      "[Epoch 43, Step 600] Loss: 5.5324, Acc: 0.3402\n",
      "[Epoch 43, Step 700] Loss: 4.9636, Acc: 0.3976\n",
      "Epoch 43 Completed - Avg Loss: 5.4727, Avg Acc: 0.3466\n",
      "[Epoch 44, Step 0] Loss: 5.0437, Acc: 0.4023\n",
      "[Epoch 44, Step 100] Loss: 4.8890, Acc: 0.4333\n",
      "[Epoch 44, Step 200] Loss: 5.4660, Acc: 0.3696\n",
      "[Epoch 44, Step 300] Loss: 5.7312, Acc: 0.3091\n",
      "[Epoch 44, Step 400] Loss: 5.3296, Acc: 0.3684\n",
      "[Epoch 44, Step 500] Loss: 5.7505, Acc: 0.3404\n",
      "[Epoch 44, Step 600] Loss: 5.6905, Acc: 0.3232\n",
      "[Epoch 44, Step 700] Loss: 5.5202, Acc: 0.3542\n",
      "Epoch 44 Completed - Avg Loss: 5.4654, Avg Acc: 0.3467\n",
      "[Epoch 45, Step 0] Loss: 5.4804, Acc: 0.3404\n",
      "[Epoch 45, Step 100] Loss: 5.5841, Acc: 0.3434\n",
      "[Epoch 45, Step 200] Loss: 5.8656, Acc: 0.2981\n",
      "[Epoch 45, Step 300] Loss: 5.3187, Acc: 0.3511\n",
      "[Epoch 45, Step 400] Loss: 5.5751, Acc: 0.3333\n",
      "[Epoch 45, Step 500] Loss: 5.4947, Acc: 0.3820\n",
      "[Epoch 45, Step 600] Loss: 5.7521, Acc: 0.3491\n",
      "[Epoch 45, Step 700] Loss: 5.4294, Acc: 0.3182\n",
      "Epoch 45 Completed - Avg Loss: 5.4552, Avg Acc: 0.3470\n",
      "[Epoch 46, Step 0] Loss: 5.2969, Acc: 0.3523\n",
      "[Epoch 46, Step 100] Loss: 5.5564, Acc: 0.3765\n",
      "[Epoch 46, Step 200] Loss: 5.7109, Acc: 0.3009\n",
      "[Epoch 46, Step 300] Loss: 5.2909, Acc: 0.3820\n",
      "[Epoch 46, Step 400] Loss: 5.4367, Acc: 0.3167\n",
      "[Epoch 46, Step 500] Loss: 5.6990, Acc: 0.3263\n",
      "[Epoch 46, Step 600] Loss: 5.4304, Acc: 0.3048\n",
      "[Epoch 46, Step 700] Loss: 5.7415, Acc: 0.3333\n",
      "Epoch 46 Completed - Avg Loss: 5.4484, Avg Acc: 0.3468\n",
      "[Epoch 47, Step 0] Loss: 5.4862, Acc: 0.3271\n",
      "[Epoch 47, Step 100] Loss: 5.6153, Acc: 0.3187\n",
      "[Epoch 47, Step 200] Loss: 5.4436, Acc: 0.3370\n",
      "[Epoch 47, Step 300] Loss: 5.5979, Acc: 0.3505\n",
      "[Epoch 47, Step 400] Loss: 5.6215, Acc: 0.3333\n",
      "[Epoch 47, Step 500] Loss: 5.6985, Acc: 0.3235\n",
      "[Epoch 47, Step 600] Loss: 5.4624, Acc: 0.3107\n",
      "[Epoch 47, Step 700] Loss: 5.6594, Acc: 0.3267\n",
      "Epoch 47 Completed - Avg Loss: 5.4427, Avg Acc: 0.3474\n",
      "[Epoch 48, Step 0] Loss: 5.2000, Acc: 0.3596\n",
      "[Epoch 48, Step 100] Loss: 5.8653, Acc: 0.3077\n",
      "[Epoch 48, Step 200] Loss: 5.3709, Acc: 0.3750\n",
      "[Epoch 48, Step 300] Loss: 6.0639, Acc: 0.2991\n",
      "[Epoch 48, Step 400] Loss: 4.8641, Acc: 0.3793\n",
      "[Epoch 48, Step 500] Loss: 5.0913, Acc: 0.3913\n",
      "[Epoch 48, Step 600] Loss: 6.0529, Acc: 0.3036\n",
      "[Epoch 48, Step 700] Loss: 5.3125, Acc: 0.3511\n",
      "Epoch 48 Completed - Avg Loss: 5.4345, Avg Acc: 0.3476\n",
      "[Epoch 49, Step 0] Loss: 5.1438, Acc: 0.3587\n",
      "[Epoch 49, Step 100] Loss: 5.4661, Acc: 0.3478\n",
      "[Epoch 49, Step 200] Loss: 5.3559, Acc: 0.3400\n",
      "[Epoch 49, Step 300] Loss: 5.7966, Acc: 0.3125\n",
      "[Epoch 49, Step 400] Loss: 5.1820, Acc: 0.3617\n",
      "[Epoch 49, Step 500] Loss: 5.4840, Acc: 0.3204\n",
      "[Epoch 49, Step 600] Loss: 5.2759, Acc: 0.3579\n",
      "[Epoch 49, Step 700] Loss: 5.3055, Acc: 0.3500\n",
      "Epoch 49 Completed - Avg Loss: 5.4282, Avg Acc: 0.3475\n",
      "[Epoch 50, Step 0] Loss: 5.0433, Acc: 0.3398\n",
      "[Epoch 50, Step 100] Loss: 4.9066, Acc: 0.3711\n",
      "[Epoch 50, Step 200] Loss: 5.5670, Acc: 0.3404\n",
      "[Epoch 50, Step 300] Loss: 5.3260, Acc: 0.3596\n",
      "[Epoch 50, Step 400] Loss: 5.7853, Acc: 0.2973\n",
      "[Epoch 50, Step 500] Loss: 5.3413, Acc: 0.3469\n",
      "[Epoch 50, Step 600] Loss: 5.6853, Acc: 0.2981\n",
      "[Epoch 50, Step 700] Loss: 5.2817, Acc: 0.2963\n",
      "Epoch 50 Completed - Avg Loss: 5.4210, Avg Acc: 0.3479\n",
      "CPU times: total: 15min 24s\n",
      "Wall time: 17min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,  # ÏõêÌïòÎäî ÏóêÌè≠ Ïàò\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc640fb9",
   "metadata": {},
   "source": [
    "STEP5. Î™®Îç∏ ÌèâÍ∞ÄÌïòÍ∏∞\n",
    "- Step 1ÏóêÏÑú ÏÑ†ÌÉùÌïú Ï†ÑÏ≤òÎ¶¨ Î∞©Î≤ïÏùÑ Í≥†Î†§ÌïòÏó¨ ÏûÖÎ†•Îêú Î¨∏Ïû•Ïóê ÎåÄÌï¥ÏÑú ÎåÄÎãµÏùÑ ÏñªÎäî ÏòàÏ∏° Ìï®ÏàòÎ•º ÎßåÎì≠ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac85ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÏòàÏ∏°ÏùÑ ÏúÑÌïú Decoder_inference Ìï®ÏàòÏ†ïÏùò\n",
    "\n",
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "    # Ï†ÑÏ≤òÎ¶¨\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # Ïù∏ÏΩîÎçî ÏûÖÎ†•: [START] + Ïù∏ÏΩîÎî© + [END]\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # Ï∞®Ïõê ÌôïÏû•: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # ÎîîÏΩîÎçî ÏûÖÎ†•(dec_input)ÏùÑ START_TOKENÎßå Ìè¨Ìï®Ìïú ÏÉÅÌÉúÎ°ú ÏãúÏûë\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # Î™®Îç∏ ÌèâÍ∞Ä Î™®Îìú\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # Î™®Îç∏ forward: (enc_input, dec_input) -> (batch_size=1, seq_len, vocab_size)\n",
    "            logits = model(enc_input, dec_input)\n",
    "\n",
    "            # ÎßàÏßÄÎßâ ÌÉÄÏûÑÏä§ÌÖùÏùò ÏòàÏ∏°Îßå Ï∂îÏ∂ú: shape (1, 1, vocab_size)\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # argmaxÎ°ú Í∞ÄÏû• ÎÜíÏùÄ ÌôïÎ•†Ïùò ÌÜ†ÌÅ∞ ÏÑ†ÌÉù\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # shape: (1,)\n",
    "\n",
    "            # Ï¢ÖÎ£å ÌÜ†ÌÅ∞Ïù¥Î©¥ Ï§ëÎã®\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # ÎîîÏΩîÎçî ÏûÖÎ†•(dec_input)Ïóê ÏòàÏ∏° ÌÜ†ÌÅ∞ÏùÑ Ïù¥Ïñ¥Î∂ôÏûÑ\n",
    "            predicted_id = predicted_id.unsqueeze(0)  # shape (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    # ÏµúÏ¢Ö ÏãúÌÄÄÏä§: dec_input: (1, seq_len)ÏóêÏÑú (seq_len,)Î°ú\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., ÌÜ†ÌÅ∞Îì§...]\n",
    "\n",
    "    return output_sequence\n",
    "\n",
    "\n",
    "\n",
    "#Ï±óÎ¥áÏùò ÎåÄÎãµÏùÑ ÏñªÎäî Ìï®Ïàò\n",
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    # ÎîîÏΩîÎçî Ïù∏ÌçºÎü∞Ïä§ -> ÏòàÏ∏°Îêú ÌÜ†ÌÅ∞ ÏãúÌÄÄÏä§\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ°ú ÎîîÏΩîÎî© (Ìå®Îî©, START/END ÌÜ†ÌÅ∞ Îì±ÏùÄ Ï†úÏô∏ÌïòÍ±∞ÎÇò Ï≤òÎ¶¨)\n",
    "    # Ïó¨Í∏∞ÏÑúÎäî Îã®ÏàúÌûà tokenizer.decode() ÏßÅÏ†ë Ìò∏Ï∂ú\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"ÏûÖÎ†• :\", sentence)\n",
    "    #print(\"Ï∂úÎ†• :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ddc9dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏûÖÎ†• : Ïñ¥ÎîîÏûàÏóàÏñ¥?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ï¢ãÏùÄ Í±∞ÏòàÏöî .'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Ïñ¥ÎîîÏûàÏóàÏñ¥?'\n",
    "sentence_generation(model, sentence, sp, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd3c781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏûÖÎ†• : Ïù¥Í±¥ Ìï®Ï†ïÏù¥Ïïº\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ï¢ãÏùÄ Í±∞ÏòàÏöî .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Ïù¥Í±¥ Ìï®Ï†ïÏù¥Ïïº\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e868dd0",
   "metadata": {},
   "source": [
    "ÌïúÍµ≠Ïñ¥ Ï†ÑÏ≤òÎ¶¨Î•º ÌÜµÌï¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Íµ¨Ï∂ï\n",
    "    - Í≥µÎ∞±Í≥º ÌäπÏàòÎ¨∏Ïûê Ï≤òÎ¶¨, ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï, Î≥ëÎ†¨Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ïÏùò Í≥ºÏ†ïÏù¥ Ï†ÅÏ†àÌûà ÏßÑÌñâÎêòÏóàÎã§.\n",
    "\n",
    "Ìä∏ÎûúÏä§Ìè¨Î®∏ Î™®Îç∏ÏùÑ Íµ¨ÌòÑÌïòÏó¨ ÌïúÍµ≠Ïñ¥ Ï±óÎ¥á Î™®Îç∏ ÌïôÏäµÏùÑ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏßÑÌñâ\n",
    "    - Íµ¨ÌòÑÌïú Ìä∏ÎûúÏä§Ìè¨Î®∏ Î™®Îç∏Ïù¥ ÌïúÍµ≠Ïñ¥ Î≥ëÎ†π Îç∞Ïù¥ÌÑ∞ ÌïôÏäµ Ïãú ÏïàÏ†ïÏ†ÅÏúºÎ°ú ÏàòÎ†¥ÌïòÏòÄÎã§.\n",
    "\n",
    "ÌïúÍµ≠Ïñ¥ ÏûÖÎ†•Î¨∏Ïû•Ïóê ÎåÄÌï¥ ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥ÄÌïòÎäî Ìï®ÏàòÎ•º Íµ¨ÌòÑ\n",
    "    - ÌïúÍµ≠Ïñ¥ ÏûÖÎ†• Î¨∏Ïû•Ïóê Îß•ÎùΩÏù¥ ÎßûÎäî ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥ÄÏùÑ Î¶¨ÌÑ¥ÌïòÏòÄÎã§."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
